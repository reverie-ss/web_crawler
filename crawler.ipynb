{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_proxies(path=\"proxies.txt\"):\n",
    "    with open(path, \"r\") as f:\n",
    "        return [line.strip() for line in f if line.strip()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[~] Crawling: https://www.westside.com/collections/polo-t-shirts-for-men\n",
      "[~] Crawling: https://www.westside.com/collections/view-all-sale\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 135\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnest_asyncio\u001b[39;00m\n\u001b[32m    134\u001b[39m nest_asyncio.apply()\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m main()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 124\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m():\n\u001b[32m    123\u001b[39m     tasks = [crawl_domain(domain) \u001b[38;5;28;01mfor\u001b[39;00m domain \u001b[38;5;129;01min\u001b[39;00m SEED_DOMAINS]\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(*tasks)\n\u001b[32m    126\u001b[39m     \u001b[38;5;66;03m# Save results to a JSON file\u001b[39;00m\n\u001b[32m    127\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mproduct_urls.json\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py:375\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[32m    374\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m         \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    376\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    377\u001b[39m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[32m    378\u001b[39m         \u001b[38;5;28mself\u001b[39m.__step(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py:304\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    300\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    301\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    302\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    303\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    306\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 108\u001b[39m, in \u001b[36mcrawl_domain\u001b[39m\u001b[34m(domain)\u001b[39m\n\u001b[32m    105\u001b[39m visited.add(url)\n\u001b[32m    107\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[~] Crawling: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m html = \u001b[38;5;28;01mawait\u001b[39;00m fetch(session, url)\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m html:\n\u001b[32m    110\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 67\u001b[39m, in \u001b[36mfetch\u001b[39m\u001b[34m(session, url, retries)\u001b[39m\n\u001b[32m     64\u001b[39m proxy = random.choice(PROXIES) \u001b[38;5;28;01mif\u001b[39;00m PROXIES \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     65\u001b[39m kwargs = {\u001b[33m\"\u001b[39m\u001b[33mproxy\u001b[39m\u001b[33m\"\u001b[39m: proxy} \u001b[38;5;28;01mif\u001b[39;00m proxy \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m session.get(url, headers=headers, timeout=\u001b[32m10\u001b[39m, **kwargs) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m response.status != \u001b[32m200\u001b[39m:\n\u001b[32m     69\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBlocked with status \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/web_crawler/.venv/lib/python3.13/site-packages/aiohttp/client.py:1425\u001b[39m, in \u001b[36m_BaseRequestContextManager.__aenter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1424\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__aenter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> _RetType:\n\u001b[32m-> \u001b[39m\u001b[32m1425\u001b[39m     \u001b[38;5;28mself\u001b[39m._resp: _RetType = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._coro\n\u001b[32m   1426\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._resp.\u001b[34m__aenter__\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/web_crawler/.venv/lib/python3.13/site-packages/aiohttp/client.py:703\u001b[39m, in \u001b[36mClientSession._request\u001b[39m\u001b[34m(self, method, str_or_url, params, data, json, cookies, headers, skip_auto_headers, auth, allow_redirects, max_redirects, compress, chunked, expect100, raise_for_status, read_until_eof, proxy, proxy_auth, timeout, verify_ssl, fingerprint, ssl_context, ssl, server_hostname, proxy_headers, trace_request_ctx, read_bufsize, auto_decompress, max_line_size, max_field_size)\u001b[39m\n\u001b[32m    701\u001b[39m \u001b[38;5;66;03m# connection timeout\u001b[39;00m\n\u001b[32m    702\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m     conn = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connector.connect(\n\u001b[32m    704\u001b[39m         req, traces=traces, timeout=real_timeout\n\u001b[32m    705\u001b[39m     )\n\u001b[32m    706\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m asyncio.TimeoutError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    707\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ConnectionTimeoutError(\n\u001b[32m    708\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mConnection timeout to host \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    709\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/web_crawler/.venv/lib/python3.13/site-packages/aiohttp/connector.py:548\u001b[39m, in \u001b[36mBaseConnector.connect\u001b[39m\u001b[34m(self, req, traces, timeout)\u001b[39m\n\u001b[32m    546\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m trace \u001b[38;5;129;01min\u001b[39;00m traces:\n\u001b[32m    547\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m trace.send_connection_create_start()\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m proto = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_connection(req, traces, timeout)\n\u001b[32m    549\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m traces:\n\u001b[32m    550\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m trace \u001b[38;5;129;01min\u001b[39;00m traces:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/web_crawler/.venv/lib/python3.13/site-packages/aiohttp/connector.py:1056\u001b[39m, in \u001b[36mTCPConnector._create_connection\u001b[39m\u001b[34m(self, req, traces, timeout)\u001b[39m\n\u001b[32m   1054\u001b[39m     _, proto = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_proxy_connection(req, traces, timeout)\n\u001b[32m   1055\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m     _, proto = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_direct_connection(req, traces, timeout)\n\u001b[32m   1058\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m proto\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/web_crawler/.venv/lib/python3.13/site-packages/aiohttp/connector.py:1351\u001b[39m, in \u001b[36mTCPConnector._create_direct_connection\u001b[39m\u001b[34m(self, req, traces, timeout, client_error)\u001b[39m\n\u001b[32m   1346\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m port \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1347\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1348\u001b[39m     \u001b[38;5;66;03m# Cancelling this lookup should not cancel the underlying lookup\u001b[39;00m\n\u001b[32m   1349\u001b[39m     \u001b[38;5;66;03m#  or else the cancel event will get broadcast to all the waiters\u001b[39;00m\n\u001b[32m   1350\u001b[39m     \u001b[38;5;66;03m#  across all connections.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1351\u001b[39m     hosts = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._resolve_host(host, port, traces=traces)\n\u001b[32m   1352\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m   1353\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc.errno \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, asyncio.TimeoutError):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/web_crawler/.venv/lib/python3.13/site-packages/aiohttp/connector.py:995\u001b[39m, in \u001b[36mTCPConnector._resolve_host\u001b[39m\u001b[34m(self, host, port, traces)\u001b[39m\n\u001b[32m    992\u001b[39m     resolved_host_task.add_done_callback(\u001b[38;5;28mself\u001b[39m._resolve_host_tasks.discard)\n\u001b[32m    994\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m995\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.shield(resolved_host_task)\n\u001b[32m    996\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m asyncio.CancelledError:\n\u001b[32m    998\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop_exception\u001b[39m(fut: \u001b[33m\"\u001b[39m\u001b[33masyncio.Future[List[ResolveResult]]\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/futures.py:286\u001b[39m, in \u001b[36mFuture.__await__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    285\u001b[39m     \u001b[38;5;28mself\u001b[39m._asyncio_future_blocking = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# This tells Task to wait for completion.\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    288\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mawait wasn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt used with future\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py:375\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[32m    374\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m         \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    376\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    377\u001b[39m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[32m    378\u001b[39m         \u001b[38;5;28mself\u001b[39m.__step(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/futures.py:194\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the result this future represents.\u001b[39;00m\n\u001b[32m    188\u001b[39m \n\u001b[32m    189\u001b[39m \u001b[33;03mIf the future has been cancelled, raises CancelledError.  If the\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[33;03mfuture's result isn't yet available, raises InvalidStateError.  If\u001b[39;00m\n\u001b[32m    191\u001b[39m \u001b[33;03mthe future is done and has an exception set, this exception is raised.\u001b[39;00m\n\u001b[32m    192\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == _CANCELLED:\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_cancelled_error()\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state != _FINISHED:\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.InvalidStateError(\u001b[33m'\u001b[39m\u001b[33mResult is not ready.\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "\n",
    "# Initial seed domains\n",
    "SEED_DOMAINS = [\n",
    "    # \"https:#www.virgio.com\",\n",
    "    # \"https:#www.tatacliq.com\",\n",
    "    # \"https:#www.nykaafashion.com\",\n",
    "    \"https:#www.westside.com/collections/polo-t-shirts-for-men\"\n",
    "]\n",
    "\n",
    "# Product URL patterns\n",
    "PRODUCT_PATTERNS = [r'/product/', r'/p/', r'/item/', r'/shop/', r'/details/', r'/sku/']\n",
    "\n",
    "# Max pages to crawl per domain to avoid infinite crawling\n",
    "MAX_PAGES = 1000\n",
    "HEADERS = {\n",
    "    \"User-Agent\": random.choice([\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:91.0) Gecko/20100101 Firefox/91.0\",\n",
    "        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36\",\n",
    "        \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "        \"CrawltonBot/1.0 (+https:#github.com/yourgithub/crawlton)\",\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36\",\n",
    "        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 11_2_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\",\n",
    "        \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:89.0) Gecko/20100101 Firefox/89.0\",\n",
    "        \"Mozilla/5.0 (iPhone; CPU iPhone OS 14_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Mobile/15E148 Safari/604.1\"\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Optional: list of proxies (use real proxies here)\n",
    "PROXIES = load_proxies()\n",
    "\n",
    "# Storage for output\n",
    "results = {}\n",
    "\n",
    "import random\n",
    "import asyncio\n",
    "\n",
    "# List of real user agents\n",
    "USER_AGENTS = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 13_2_1) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.3 Safari/605.1.15\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\",\n",
    "    # Add more if you like\n",
    "]\n",
    "\n",
    "# Optional: list of proxies (use real proxies here)\n",
    "PROXIES = [\n",
    "    # \"http:#user:pass@proxy1.com:port\",\n",
    "    # \"http:#proxy2.com:port\",\n",
    "]\n",
    "\n",
    "async def fetch(session, url, retries=3):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            headers = {\n",
    "                \"User-Agent\": random.choice(USER_AGENTS)\n",
    "            }\n",
    "            proxy = random.choice(PROXIES) if PROXIES else None\n",
    "            kwargs = {\"proxy\": proxy} if proxy else {}\n",
    "\n",
    "            async with session.get(url, headers=headers, timeout=10, **kwargs) as response:\n",
    "                if response.status != 200:\n",
    "                    raise Exception(f\"Blocked with status {response.status}\")\n",
    "                if 'text/html' in response.headers.get('Content-Type', ''):\n",
    "                    return await response.text()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[!] Fetch failed ({attempt + 1}/{retries}) {url}: {e}\")\n",
    "            await asyncio.sleep(2 ** attempt + random.random())  # exponential backoff\n",
    "\n",
    "    return None  # after all retries fail\n",
    "\n",
    "\n",
    "def extract_links(html, base_url):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    links = set()\n",
    "    for a in soup.find_all('a', href=True):\n",
    "        href = urljoin(base_url, a['href'])\n",
    "        if is_same_domain(base_url, href):\n",
    "            links.add(href.split('#')[0])  # Remove fragments\n",
    "    return links\n",
    "\n",
    "def is_same_domain(base, target):\n",
    "    return urlparse(base).netloc == urlparse(target).netloc\n",
    "\n",
    "def is_product_url(url):\n",
    "    return any(re.search(pattern, url) for pattern in PRODUCT_PATTERNS)\n",
    "\n",
    "async def crawl_domain(domain):\n",
    "    visited = set()\n",
    "    to_visit = set([domain])\n",
    "    product_urls = set()\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        while to_visit and len(visited) < MAX_PAGES:\n",
    "            url = to_visit.pop()\n",
    "            if url in visited:\n",
    "                continue\n",
    "            visited.add(url)\n",
    "\n",
    "            print(f\"[~] Crawling: {url}\")\n",
    "            html = await fetch(session, url)\n",
    "            if not html:\n",
    "                continue\n",
    "\n",
    "            links = extract_links(html, url)\n",
    "            for link in links:\n",
    "                if link not in visited:\n",
    "                    if is_product_url(link):\n",
    "                        print(f\"[+] Found product: {link}\")\n",
    "                        product_urls.add(link)\n",
    "                    to_visit.add(link)\n",
    "\n",
    "    results[urlparse(domain).netloc] = sorted(product_urls)\n",
    "\n",
    "async def main():\n",
    "    tasks = [crawl_domain(domain) for domain in SEED_DOMAINS]\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "    # Save results to a JSON file\n",
    "    with open(\"product_urls.json\", \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    print(\"\\n✅ Done! Product URLs saved to 'product_urls.json'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "    await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML fetched successfully!\n"
     ]
    }
   ],
   "source": [
    "# Fetch HTML from the given endpoint\n",
    "url = \"https:#www.westside.com/collections/polo-t-shirts-for-men\"\n",
    "\n",
    "async def fetch_html():\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        html = await fetch(session, url)\n",
    "        if html:\n",
    "            print(\"HTML fetched successfully!\")\n",
    "            return html\n",
    "        else:\n",
    "            print(\"Failed to fetch HTML.\")\n",
    "            return None\n",
    "\n",
    "# Run the fetch_html coroutine\n",
    "html_content = await fetch_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred while launching the browser: Page.wait_for_selector: Timeout 15000ms exceeded.\n",
      "Call log:\n",
      "  - waiting for locator(\".product-title\") to be visible\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from playwright.async_api import async_playwright\n",
    "from bs4 import BeautifulSoup\n",
    "import asyncio\n",
    "# Fetch HTML from the given endpoint\n",
    "# url = \"https://www.westside.com/collections/polo-t-shirts-for-men\"\n",
    "# url = \"https://www.tatacliq.com/mens-clothing-casual-wear-t-shirts-polos/c-msh1116100\"\n",
    "# url = \"https://www.virgio.com/collections/the-party-edit\"\n",
    "url = \"https://www.nykaafashion.com/women/westernwear/shirts/c/7623\"\n",
    "\n",
    "\n",
    "\n",
    "async def slow_scroll_to_bottom(page, step=500, delay=0.5):\n",
    "    scroll_count = 1\n",
    "    while True:\n",
    "        previous_height = step * scroll_count\n",
    "        await page.evaluate(f\"window.scrollBy(0, {step})\")\n",
    "        time.sleep(delay)\n",
    "\n",
    "        new_height = await page.evaluate(\"() => document.body.scrollHeight\")\n",
    "        if previous_height > new_height:\n",
    "            break\n",
    "        scroll_count += 1\n",
    "        if scroll_count > 10:\n",
    "            break\n",
    "\n",
    "async def scroll_to_bottom(page, scroll_delay=2.0, max_scrolls=50):\n",
    "    \"\"\"Scrolls to the bottom of the page to load dynamic content.\"\"\"\n",
    "    previous_height = await page.evaluate(\"() => document.body.scrollHeight\")\n",
    "    \n",
    "    for _ in range(max_scrolls):\n",
    "        await page.evaluate(f\"window.scrollTo(0, {int(previous_height*0.8)})\")\n",
    "        time.sleep(scroll_delay)\n",
    "        \n",
    "        new_height = await page.evaluate(\"() => document.body.scrollHeight\")\n",
    "        if new_height == previous_height:\n",
    "            break\n",
    "        previous_height = new_height\n",
    "\n",
    "async def fetch_rendered_html(url):\n",
    "    try:\n",
    "        async with async_playwright() as p:\n",
    "            browser = await p.chromium.launch(headless=False)\n",
    "            page = await browser.new_page()\n",
    "            # async def block_requests(route, request):\n",
    "            #     if request.resource_type in [\"image\", \"stylesheet\", \"font\", \"media\"]:\n",
    "            #         await route.abort()\n",
    "            #     else:\n",
    "            #         await route.continue_()\n",
    "\n",
    "            # await page.route(\"**/*\", block_requests)\n",
    "            await page.goto(url)\n",
    "            await page.wait_for_load_state(\"networkidle\")\n",
    "            await page.wait_for_selector(\".product-title\", timeout=15000)\n",
    "            # await page.wait_for_selector(\"img\", timeout=10000)\n",
    "            # await slow_scroll_to_bottom(page)\n",
    "            time.sleep(5)\n",
    "            content = await page.content()\n",
    "            await browser.close()\n",
    "            return content\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while launching the browser: {e}\")\n",
    "\n",
    "# Fetch the fully rendered HTML\n",
    "html_content = await fetch_rendered_html(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urljoin, urlparse\n",
    "filtered_link = []\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "base_url = urlparse(url)\n",
    "base_url = f\"{base_url.scheme}://{base_url.netloc}\"\n",
    "for tag in soup.find_all(href=True):\n",
    "    if tag.name == \"link\":\n",
    "        continue\n",
    "    link = tag.get(\"href\", None)\n",
    "    if link is None:\n",
    "        continue\n",
    "    if link.startswith(\"/\"):\n",
    "        link = urljoin(base_url, link)\n",
    "    if urlparse(link).netloc == urlparse(url).netloc:\n",
    "            if link not in filtered_link:\n",
    "                filtered_link.append(link.split('?')[0])  # Remove fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML content has been saved to 'rendered_page.html'.\n"
     ]
    }
   ],
   "source": [
    "# Save the HTML content to a file\n",
    "with open(\"rendered_page.html\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(html_content)\n",
    "\n",
    "print(\"HTML content has been saved to 'rendered_page.html'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121,\n",
       " ['https://www.nykaafashion.com/',\n",
       "  'https://www.nykaafashion.com/women/c/6557',\n",
       "  'https://www.nykaafashion.com/men/c/6823',\n",
       "  'https://www.nykaafashion.com/kids/c/6266',\n",
       "  'https://www.nykaafashion.com/home/c/8528',\n",
       "  'https://www.nykaafashion.com/all-brands',\n",
       "  'https://www.nykaafashion.com/lp/luxe',\n",
       "  'https://www.nykaafashion.com/lp/hidden-gems',\n",
       "  'https://www.nykaafashion.com/lp/global-store',\n",
       "  'https://www.nykaafashion.com/lp/revolve',\n",
       "  'https://www.nykaafashion.com/lp/fit-zone',\n",
       "  'https://www.nykaafashion.com/women/westernwear/c/3',\n",
       "  'https://www.nykaafashion.com/the-souled-store-originals-blooming-women-boyfriend-shirt/p/17277862',\n",
       "  'https://www.nykaafashion.com/dl-woman-blue-oversized-vertical-stripes-pure-cotton-oxford-casual-shirt/p/16046772',\n",
       "  'https://www.nykaafashion.com/campus-sutra-womens-blue-buffalo-check-cinched-cropped-shirt/p/14813904',\n",
       "  'https://www.nykaafashion.com/vero-moda-disney-dark-olive-printed-shacket/p/17866913',\n",
       "  'https://www.nykaafashion.com/twenty-dresses-by-nykaa-fashion-light-green-full-sleeves-crop-shirt/p/18108123',\n",
       "  'https://www.nykaafashion.com/cider-collar-patchwork-button-long-sleeve-blouse-top/p/17288974',\n",
       "  'https://www.nykaafashion.com/styli-solid-satin-collared-blouse/p/10749413',\n",
       "  'https://www.nykaafashion.com/shaye-women-yellow-embroidered-half-sleeves-casual-shirt/p/16349922',\n",
       "  'https://www.nykaafashion.com/pinacolada-women-s-purple-ribbed-striped-shirt/p/17559415',\n",
       "  'https://www.nykaafashion.com/fablestreet-pink-satin-stripes-shirt/p/16355515',\n",
       "  'https://www.nykaafashion.com/high-star-women-cotton-spread-collar-long-sleeves-oversized-shirts/p/13154994',\n",
       "  'https://www.nykaafashion.com/the-souled-store-peanuts-comic-print-women-boyfriend-shirt/p/9572677',\n",
       "  'https://www.nykaafashion.com/campus-sutra-women-s-lilac-off-white-pencil-striped-oversized-shirt/p/18333690',\n",
       "  'https://www.nykaafashion.com/dl-woman-white-full-sleeves-oversized-solid-casual-shirt/p/16046781',\n",
       "  'https://www.nykaafashion.com/twenty-dresses-by-nykaa-fashion-red-and-white-stripes-pointed-collar-shirt/p/14350381',\n",
       "  'https://www.nykaafashion.com/pinacolada-women-s-mocha-brown-ribbed-striped-shirt/p/17559414',\n",
       "  'https://www.nykaafashion.com/shaye-women-purple-embroidered-half-sleeves-casual-shirt/p/16349923',\n",
       "  'https://www.nykaafashion.com/fablestreet-olive-folded-sleeve-top/p/446885',\n",
       "  'https://www.nykaafashion.com/athena-self-design-shirt-collar-schiffli-cotton-white-shirt/p/16173652',\n",
       "  'https://www.nykaafashion.com/anvi-be-yourself-women-green-comfort-tailored-fit-printed-casual-shirt/p/9889227',\n",
       "  'https://www.nykaafashion.com/purys-pink-casual-linen-shirt/p/18715722',\n",
       "  'https://www.nykaafashion.com/style-quotient-women-white-solid-shirts/p/6890340',\n",
       "  'https://www.nykaafashion.com/campus-sutra-women-powder-blue-and-blush-pink-balanced-striped-oversized-shirt/p/18260949',\n",
       "  'https://www.nykaafashion.com/vero-moda-white-printed-regular-fit-shirt/p/20105508',\n",
       "  'https://www.nykaafashion.com/dl-woman-black-abstract-printed-spread-collar-oversized-casual-shirt/p/16046792',\n",
       "  'https://www.nykaafashion.com/the-souled-store-tss-originals-bloom-shirts-for-womens/p/12353941',\n",
       "  'https://www.nykaafashion.com/shaye-womens-collar-neck-pink-embellished-long-sleeves-party-shirt/p/16413758',\n",
       "  'https://www.nykaafashion.com/twenty-dresses-by-nykaa-fashion-work-black-solid-full-sleeves-smocked-cropped-shirt/p/11329170',\n",
       "  'https://www.nykaafashion.com/women/westernwear/shirts/c/7623',\n",
       "  'https://www.nykaafashion.com/women/westernwear/jeans-and-jeggings/c/6264',\n",
       "  'https://www.nykaafashion.com/women/westernwear/jackets-and-coats/c/5262',\n",
       "  'https://www.nykaafashion.com/women/accessories/watches/c/4641',\n",
       "  'https://www.nykaafashion.com/women/footwear/heels/c/3523',\n",
       "  'https://www.nykaafashion.com/high-star-women-white-long-sleeves-solid-oversized-casual-shirt/p/12465817',\n",
       "  'https://www.nykaafashion.com/campus-sutra-women-aegean-blue-chalk-white-candy-striped-boyfriend-shirt/p/13775625',\n",
       "  'https://www.nykaafashion.com/lp/about-us',\n",
       "  'https://www.nykaafashion.com/lp/careers',\n",
       "  'https://www.nykaafashion.com/lp/about-us',\n",
       "  'https://www.nykaafashion.com/lp/shipping-and-return-policy',\n",
       "  'https://www.nykaafashion.com/gateway-api/omsApis/helpCenter',\n",
       "  'https://www.nykaafashion.com/lp/terms-and-conditions',\n",
       "  'https://www.nykaafashion.com/lp/privacy-policy',\n",
       "  'https://www.nykaafashion.com/lp/responsible-disclosure',\n",
       "  'https://www.nykaafashion.com/cp/sellonnykaa',\n",
       "  'https://www.nykaafashion.com/offer.html',\n",
       "  'https://www.nykaafashion.com/cp/sitemap',\n",
       "  'https://www.nykaafashion.com/style-files/',\n",
       "  'https://www.nykaafashion.com/women/indianwear/c/4',\n",
       "  'https://www.nykaafashion.com/women/bags/c/89',\n",
       "  'https://www.nykaafashion.com/women/footwear/c/3528',\n",
       "  'https://www.nykaafashion.com/women/jewellery/c/77',\n",
       "  'https://www.nykaafashion.com/women/lingerie/c/3946',\n",
       "  'https://www.nykaafashion.com/women/sportswear/c/4015',\n",
       "  'https://www.nykaafashion.com/women/lingerie/sleepwear/c/3986',\n",
       "  'https://www.nykaafashion.com/women/accessories/c/104',\n",
       "  'https://www.nykaafashion.com/men/topwear/c/6824',\n",
       "  'https://www.nykaafashion.com/men/bottoms/c/6834',\n",
       "  'https://www.nykaafashion.com/men/ethnicwear/c/6841',\n",
       "  'https://www.nykaafashion.com/men/footwear/c/6857',\n",
       "  'https://www.nykaafashion.com/men/personal-accessories/c/6879',\n",
       "  'https://www.nykaafashion.com/men/innerwear-sleepwear/c/6850',\n",
       "  'https://www.nykaafashion.com/men/watches/c/6875',\n",
       "  'https://www.nykaafashion.com/men/bags/c/6867',\n",
       "  'https://www.nykaafashion.com/men/sports-and-athleisure/c/6888',\n",
       "  'https://www.nykaafashion.com/sports-fitness-equipment/c/11219',\n",
       "  'https://www.nykaafashion.com/kids/indianwear/c/6267',\n",
       "  'https://www.nykaafashion.com/kids/westernwear/c/6282',\n",
       "  'https://www.nykaafashion.com/kids/footwear/c/6333',\n",
       "  'https://www.nykaafashion.com/kids/accessories/jewelry/c/6348',\n",
       "  'https://www.nykaafashion.com/kids/feeding/c/6351',\n",
       "  'https://www.nykaafashion.com/kids/sportswear/c/6298',\n",
       "  'https://www.nykaafashion.com/kids/sleepwear/c/6372',\n",
       "  'https://www.nykaafashion.com/kids/accessories/c/6343',\n",
       "  'https://www.nykaafashion.com/kids/toys-and-games/c/6382',\n",
       "  'https://www.nykaafashion.com/kids/innerwear/c/6329',\n",
       "  'https://www.nykaafashion.com/luxe-indian-wear/c/12039',\n",
       "  'https://www.nykaafashion.com/luxe-western-wear/c/12038',\n",
       "  'https://www.nykaafashion.com/luxe-footwear/c/12041',\n",
       "  'https://www.nykaafashion.com/luxe-bags/c/12042',\n",
       "  'https://www.nykaafashion.com/luxe-accessories/c/12043',\n",
       "  'https://www.nykaafashion.com/luxe-watches/c/12200',\n",
       "  'https://www.nykaafashion.com/luxe-home-edit/c/12045',\n",
       "  'https://www.nykaafashion.com/luxe-jewellery/c/12040',\n",
       "  'https://www.nykaafashion.com/luxe-summer-collection/c/12114',\n",
       "  'https://www.nykaafashion.com/fluid-flowing-luxe/c/6002',\n",
       "  'https://www.nykaafashion.com/designers/puma/c/4886',\n",
       "  'https://www.nykaafashion.com/designers/vero-moda/c/4188',\n",
       "  'https://www.nykaafashion.com/designers/w/c/4038',\n",
       "  'https://www.nykaafashion.com/designers/biba/c/5274',\n",
       "  'https://www.nykaafashion.com/designers/forever-new/c/4495',\n",
       "  'https://www.nykaafashion.com/designers/skechers/c/6477',\n",
       "  'https://www.nykaafashion.com/designers/fablestreet/c/1970',\n",
       "  'https://www.nykaafashion.com/designers/only/c/4189',\n",
       "  'https://www.nykaafashion.com/designers/autumnlane/c/12071',\n",
       "  'https://www.nykaafashion.com/designers/cider/c/15204',\n",
       "  'https://www.nykaafashion.com/designers/accessorize-london/c/6748',\n",
       "  'https://www.nykaafashion.com/twenty-dresses-by-nykaa-fashion/c/4240',\n",
       "  'https://www.nykaafashion.com/designers/nykd-by-nykaa/c/7059',\n",
       "  'https://www.nykaafashion.com/designers/rsvp/c/4706',\n",
       "  'https://www.nykaafashion.com/designers/gajra-gang/c/10009',\n",
       "  'https://www.nykaafashion.com/designers/likha/c/11935',\n",
       "  'https://www.nykaafashion.com/designers/mixt-by-nykaa-fashion/c/15963',\n",
       "  'https://www.nykaafashion.com/designers/iykyk-by-nykaa-fashion/c/11495',\n",
       "  'https://www.nykaafashion.com/designers/kica/c/4629',\n",
       "  'https://www.nykaafashion.com/designers/pipa-bella-by-nykaa-fashion/c/3771',\n",
       "  'https://www.nykaafashion.com/designers/azai-jewellery-by-nykaa-fashion/c/13718',\n",
       "  'https://www.nykaafashion.com/designers/twig-twine/c/12291',\n",
       "  'https://www.nykaafashion.com/designers/gloot/c/13564',\n",
       "  'https://www.nykaafashion.com/designers/nyri/c/14963'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_link), filtered_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common pattern group:\n",
      "https://www.westside.com/products/wes-casuals-navy-relaxed-fit-cotton-blend-polo-t-shirt-301018311?variant=44435570753589\n",
      "https://www.westside.com/products/wes-casuals-navy-relaxed-fit-cotton-blend-polo-t-shirt-301017166?variant=44422146097205\n",
      "https://www.westside.com/products/wes-casuals-navy-relaxed-fit-cotton-blend-polo-t-shirt-301007874?variant=44239568306229\n",
      "https://www.westside.com/products/wes-casuals-navy-relaxed-fit-cotton-blend-polo-t-shirt-301014061?variant=44380880142389\n",
      "https://www.westside.com/products/wes-casuals-navy-relaxed-fit-cotton-blend-polo-t-shirt-301010198?variant=44360037466165\n",
      "https://www.westside.com/products/wes-casuals-navy-relaxed-fit-cotton-blend-polo-t-shirt-301013303?variant=44384219824181\n",
      "https://www.westside.com/products/wes-casuals-navy-relaxed-fit-cotton-blend-polo-t-shirt-301018314?variant=44404898398261\n",
      "https://www.westside.com/products/wes-casuals-navy-relaxed-fit-cotton-blend-polo-t-shirt-301013005?variant=44384219365429\n",
      "https://www.westside.com/products/wes-casuals-navy-relaxed-fit-cotton-blend-polo-t-shirt-301016176?variant=44370094620725\n",
      "https://www.westside.com/products/wes-casuals-navy-relaxed-fit-cotton-blend-polo-t-shirt-301010978?variant=44312449613877\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "from collections import defaultdict, Counter\n",
    "import re\n",
    "\n",
    "# Sample list of URLs\n",
    "urls = filtered_link\n",
    "\n",
    "# Optional: Remove query params\n",
    "def clean_url(url):\n",
    "    parsed = urlparse(url)\n",
    "    return parsed.scheme + \"://\" + parsed.netloc + parsed.path\n",
    "\n",
    "# Step 1: Clean and group by pattern\n",
    "def get_pattern(url):\n",
    "    url = clean_url(url)\n",
    "    # Replace numeric parts with {id}\n",
    "    pattern = re.sub(r'\\d+', '{id}', url)\n",
    "    return pattern\n",
    "\n",
    "# Step 2: Build groups\n",
    "group_map = defaultdict(list)\n",
    "for url in urls:\n",
    "    pattern = get_pattern(url)\n",
    "    group_map[pattern].append(url)\n",
    "\n",
    "# Step 3: Find the most frequent group\n",
    "most_common_group = max(group_map.values(), key=len)\n",
    "\n",
    "# Output\n",
    "print(\"Most common pattern group:\")\n",
    "for u in most_common_group:\n",
    "    print(u)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
